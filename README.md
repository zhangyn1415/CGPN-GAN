# CGPN-GAN
CLIP-Guided Generative Network for Pathology Nuclei Image Augmentation

Coming soon....

### CLIP model
QuiltNet (https://huggingface.co/wisdomik/QuiltNet-B-32)

### Datasets
1. PanNuke (https://warwick.ac.uk/fac/sci/dcs/research/tia/data/pannuke)
2. Lizard (https://www.kaggle.com/datasets/aadimator/lizard-dataset)
3. EndoNuke (https://endonuke.ispras.ru/)
4. PUMA (https://zenodo.org/records/13859989)
5. NuInsSeg (https://www.kaggle.com/datasets/ipateam/nuinsseg)
6. MonuSeg (https://www.kaggle.com/datasets/tuanledinh/monuseg2018)

#### Textual description generation
### for PanNuke dataset
 preprocess.py 

## Training
  train.py

## Sampling
 test.py

---
### Citing CGPN-GAN

**Reference**
- [Semantic Image Synthesis with Spatially-Adaptive Normalization] (https://github.com/NVlabs/SPADE)
- [GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis] (https://github.com/tobran/GALIP)
